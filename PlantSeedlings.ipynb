{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PlantSeedlings.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RliL1g2Dm5V2"
      },
      "source": [
        "### **Plant Seedlings Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taTDNzZknU81"
      },
      "source": [
        "In this project, let us import the images of various plant seedlings, train the images & then predict the seedlings family. First, we will try to predict with convolutional neural networks & compare it with the supervised learning classifier (like KNN) and neural networks.\r\n",
        "\r\n",
        "The dataset comprises of images from 12 plant species. Source: https://www.kaggle.com/c/plant-seedlings-classification/data\r\n",
        "\r\n",
        "Let us create a classifier capable of determining a plant's species from a photo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BINL0o3EzUMj"
      },
      "source": [
        "#Mounting the drive \r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIGCeG6lziHn"
      },
      "source": [
        "#After mounting the directory, lets check the current working directory path in Google drive\r\n",
        "import os\r\n",
        "def current_path(): \r\n",
        "    print(\"Current working directory before\") \r\n",
        "    print(os.getcwd()) \r\n",
        "    print() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZkAIGbTO7oj"
      },
      "source": [
        "# The image files are saved in the following google drive path\r\n",
        "! cd /content/drive/My\\ Drive/PlantClassification/\r\n",
        "! ls /content/drive/My\\ Drive/PlantClassification/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7JCnyYBUxqH"
      },
      "source": [
        "***Data Import & CNN***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc7Xu2_cQpHb"
      },
      "source": [
        "#Importing the basic neccesary packages. The remaining packages will be imported at later point of time on the need basis\r\n",
        "import os        \r\n",
        "import numpy as np # linear algebra\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\r\n",
        "import tensorflow as tf\r\n",
        "import PIL\r\n",
        "import PIL.Image\r\n",
        "from tensorflow import keras\r\n",
        "import tensorflow_datasets as tfds\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjfzlWtcaVsh"
      },
      "source": [
        "#Categories of Seedling available in the training folder. The respective images are saved under each folder of the categories mentioned below\r\n",
        "plant_category=os.listdir('/content/drive/MyDrive/PlantClassification/train')\r\n",
        "plant_category"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RTI_Q0nR7YX"
      },
      "source": [
        "#Import Test, Train & Validation Data\r\n",
        "\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "import cv2\r\n",
        "#Validation Train split as 20-80. We have a separate folder for Test images\r\n",
        "train_datagen =ImageDataGenerator(rescale=1./255, validation_split=0.2)\r\n",
        "test_datagen =ImageDataGenerator(rescale=1./255)\r\n",
        "\r\n",
        "    \r\n",
        "train_seedlings = train_datagen.flow_from_directory(\r\n",
        "        '/content/drive/MyDrive/PlantClassification/train',  \r\n",
        "            target_size=(224,224),  # Resizes images\r\n",
        "            batch_size=64,\r\n",
        "            class_mode='categorical',subset = 'training', seed=50)\r\n",
        "x_train,y_train=next(train_seedlings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCiXFVhNS2IB"
      },
      "source": [
        "validation_seedlings = train_datagen.flow_from_directory(\r\n",
        "    '/content/drive/MyDrive/PlantClassification/train',\r\n",
        "    target_size=(224, 224),\r\n",
        "    batch_size= 64,\r\n",
        "    class_mode='categorical',\r\n",
        "    subset='validation')\r\n",
        "\r\n",
        "x_val,y_val=next(validation_seedlings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uyg6tyB9mjq2"
      },
      "source": [
        "test_seedlings = test_datagen.flow_from_directory(\r\n",
        "    '/content/drive/My Drive/PlantClassification/test/',\r\n",
        "    target_size=(224, 224),\r\n",
        "    batch_size=64,\r\n",
        "    class_mode=None,\r\n",
        "    )\r\n",
        "\r\n",
        "x_test=next(test_seedlings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGNgoz09iBeB"
      },
      "source": [
        "#Number of images available in each of the category \r\n",
        "unique, counts = np.unique(train_seedlings.classes, return_counts=True)\r\n",
        "dict1 = dict(zip(train_seedlings.class_indices, counts))\r\n",
        "\r\n",
        "keys = dict1.keys()\r\n",
        "values = dict1.values()\r\n",
        "\r\n",
        "plt.xticks(rotation='vertical')\r\n",
        "bar = plt.bar(keys, values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6oLg_YAqcXA"
      },
      "source": [
        "#Plotting few of the images \r\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\r\n",
        "\r\n",
        "def show_grid(image_list, nrows, ncols, label_list=None, show_labels=False, figsize=(10,10)):\r\n",
        "\r\n",
        "    fig = plt.figure(None, figsize,frameon=False)\r\n",
        "    grid = ImageGrid(fig, 111, \r\n",
        "                     nrows_ncols=(nrows, ncols),  \r\n",
        "                     axes_pad=0.2, \r\n",
        "                     share_all=True,\r\n",
        "                     )\r\n",
        "    for i in range(nrows*ncols):\r\n",
        "        ax = grid[i]\r\n",
        "        ax.imshow(image_list[i],cmap='Greys_r')\r\n",
        "        ax.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FI__OHUq5ce"
      },
      "source": [
        "show_grid(x_train,2,4,show_labels=True,figsize=(10,10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QLqJlk14iy2"
      },
      "source": [
        "from keras.layers import Conv2D,MaxPooling2D,GlobalMaxPool2D\r\n",
        "from keras.layers import BatchNormalization, Activation\r\n",
        "from keras.layers import Dropout, Flatten, Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BN1cN1sBWTUY"
      },
      "source": [
        "##### ***CNN Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WjE8h3HWQv3"
      },
      "source": [
        "model = tf.keras.models.Sequential([\r\n",
        "    \r\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=train_seedlings.image_shape),\r\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\r\n",
        "    keras.layers.Dropout(rate=0.15), \r\n",
        "    \r\n",
        "    # The second convolution\r\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\r\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\r\n",
        "    keras.layers.Dropout(rate=0.10),\r\n",
        "    \r\n",
        "    # The third convolution\r\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\r\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\r\n",
        "    keras.layers.Dropout(rate=0.15),\r\n",
        "    \r\n",
        "    # Flatten the results to feed into a DNN\r\n",
        "    tf.keras.layers.Flatten(),\r\n",
        "    \r\n",
        "    # hidden layer\r\n",
        "    \r\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\r\n",
        "    keras.layers.BatchNormalization(),    #adding batch normalization\r\n",
        "    keras.layers.Dropout(rate=0.10),\r\n",
        "  \r\n",
        "    \r\n",
        "    # 12 output neurons for the 12 classes of Seedling Images\r\n",
        "    tf.keras.layers.Dense(12, activation='softmax')\r\n",
        "    \r\n",
        "    \r\n",
        "    ])\r\n",
        "\r\n",
        "from tensorflow.keras.optimizers import RMSprop\r\n",
        "\r\n",
        "model.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer=\"sgd\",\r\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0URyjSBWjCf"
      },
      "source": [
        "## Running our model for 12 epochs\r\n",
        "\r\n",
        "from tensorflow.keras import datasets, layers, models\r\n",
        "\r\n",
        "#Model fitting for a number of epochs\r\n",
        "history = model.fit(\r\n",
        "      train_seedlings,\r\n",
        "      steps_per_epoch=50,\r\n",
        "      epochs=20,\r\n",
        "      validation_data = validation_seedlings,\r\n",
        "      validation_steps = 10,\r\n",
        "      verbose=1)\r\n",
        "\r\n",
        "acc = history.history['acc']\r\n",
        "val_acc = history.history['val_acc']\r\n",
        "loss = history.history['loss']\r\n",
        "val_loss = history.history['val_loss']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdQBvNI-scse"
      },
      "source": [
        "# returns accuracy of training\r\n",
        "print(\"Training Accuracy:\"), print(history.history['acc'][-1])\r\n",
        "print(\"Validation Accuracy:\"), print (history.history['val_acc'][-1])\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10, 3))\r\n",
        "ax = ax.ravel()\r\n",
        "for i, met in enumerate(['acc', 'loss']):\r\n",
        "    ax[i].plot(history.history[met])\r\n",
        "    ax[i].plot(history.history['val_' + met])\r\n",
        "    ax[i].set_title('Model {}'.format(met))\r\n",
        "    ax[i].set_xlabel('epochs')\r\n",
        "    ax[i].set_ylabel(met)\r\n",
        "    ax[i].legend(['train', 'val'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gm6SObzqI-PB"
      },
      "source": [
        "It is seen that as epoch increases,the accuracy increases & loss decreases for training data. But Validation data doesn't follow same pattern like test. After validating the data, let us try to predict the seedlings with test data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz5HizKs_JvX"
      },
      "source": [
        "prediction=model.predict(test_seedlings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKnYjQch45dy"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "\r\n",
        "#encoding dependent variable\r\n",
        "encoder = LabelEncoder()\r\n",
        "encoder.fit(plant_category)\r\n",
        "preds = np.argmax(prediction, axis=1)\r\n",
        "pred_cat=encoder.classes_[preds]\r\n",
        "preds = np.argmax(prediction, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zo7C22w5UE_"
      },
      "source": [
        "#Final prediction\r\n",
        "final_predictions = {'file':test_seedlings.filenames, 'species':pred_cat}\r\n",
        "final_predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxyGFc24rnEX"
      },
      "source": [
        "It could be seen that CNN has accuracy around 99% in train data & 67% in test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBmrfMrhGNZj"
      },
      "source": [
        " **Supervised Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HagXr8cMsAGQ"
      },
      "source": [
        "Lets import data for supervised learning. We can reuse the dataset imported earlier also. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "payQ5HcqvNtn"
      },
      "source": [
        "train_path='/content/drive/MyDrive/PlantClassification/train/'\r\n",
        "data_dir= '/content/drive/MyDrive/PlantClassification/'\r\n",
        "test_path= '/content/drive/MyDrive/PlantClassification/test/unknown/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrhVKmcvgqpd"
      },
      "source": [
        "#Import Test, Train & Validation Data\r\n",
        "\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "import cv2\r\n",
        "\r\n",
        "train_datagen =ImageDataGenerator(rescale=1./255, validation_split=0.2)\r\n",
        "test_datagen =ImageDataGenerator(rescale=1./255)\r\n",
        "\r\n",
        "    \r\n",
        "train_seedlings = train_datagen.flow_from_directory(\r\n",
        "        '/content/drive/MyDrive/PlantClassification/train',  \r\n",
        "            target_size=(224, 224),  # Resizes images\r\n",
        "            batch_size=512,\r\n",
        "            #color_mode=\"grayscale\",\r\n",
        "            class_mode='categorical',subset = 'training', seed=50)\r\n",
        "Kx_train,Ky_train=next(train_seedlings)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSMl-PCjgqpf"
      },
      "source": [
        "validation_seedlings = train_datagen.flow_from_directory(\r\n",
        "    '/content/drive/MyDrive/PlantClassification/train',\r\n",
        "    target_size=(224, 224),\r\n",
        "    batch_size=512,\r\n",
        "    class_mode='categorical',\r\n",
        "    subset='validation')\r\n",
        "\r\n",
        "Kx_val,Ky_val=next(validation_seedlings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enblzzY1qIoU"
      },
      "source": [
        "Kx_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyrkwwUM2XCS"
      },
      "source": [
        "Kx_val.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRBdACC41PCz"
      },
      "source": [
        "Kx_train = Kx_train.reshape((Kx_train.shape[0], -1))\r\n",
        "Kx_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bzs3OQRP2a9H"
      },
      "source": [
        "Kx_val = Kx_val.reshape((Kx_val.shape[0], -1))\r\n",
        "Kx_val.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zIVxNP5X7_S"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "images = x_train[:9]\r\n",
        "labels = y_train[:9]\r\n",
        "\r\n",
        "# to visualize some images from our data set\r\n",
        "fig, axes = plt.subplots(3, 3, figsize=(2*3,2*3))\r\n",
        "for i in range(9):\r\n",
        "    ax = axes[i//3, i%3]\r\n",
        "    ax.imshow(images[i], cmap='gray')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBepfn4t21LX"
      },
      "source": [
        "Kx_train=Kx_train/255\r\n",
        "Kx_val=Kx_val/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pJgL-tv3KYa"
      },
      "source": [
        "#importing libraries\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from scipy.stats import zscore\r\n",
        "from sklearn import metrics\r\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2ZA-WG43Ro6"
      },
      "source": [
        "#Using K Nearest Neibours algorithm for the image classification  \r\n",
        "Klist=[3,5,7,9,11]\r\n",
        "Kscore = [] #to store scores\r\n",
        "\r\n",
        "#For loop to run kmodel\r\n",
        "for k in Klist:\r\n",
        "    KNN= KNeighborsClassifier(n_neighbors = k)\r\n",
        "    KNN.fit(Kx_train, Ky_train)\r\n",
        "    K_predict = KNN.predict(Kx_val)\r\n",
        "    score = accuracy_score(Ky_val,K_predict)\r\n",
        "    Kscore.append(score)\r\n",
        "\r\n",
        "#Find Mean Square Error t check optimak k\r\n",
        "MSE = [1-x for x in Kscore]\r\n",
        "\r\n",
        "optimalk = Klist[MSE.index(min(MSE))]\r\n",
        "print(\"Optimal K for this dataset is : %d\" %optimalk)\r\n",
        "\r\n",
        "#Visualising K and MSE\r\n",
        "plt.plot(Klist,MSE)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeU5HBOijqfs"
      },
      "source": [
        "KNN with k as 3 is giving 10% accuracy for this problem statement. Also from the classification report warning, we can see that few labels have not been predicted at all."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyCu1GjJjd5R"
      },
      "source": [
        "print(Kscore[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNjIxJeIUFDJ"
      },
      "source": [
        "**Neural Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC4nd5yhUDsL"
      },
      "source": [
        "We can proceed to build Neural Network model for better prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvN1mi7gEJJT"
      },
      "source": [
        "#Loading Train data\r\n",
        "train_data=[]\r\n",
        "if not train_data:\r\n",
        "  for category_id, category in enumerate(plant_category):\r\n",
        "    for file in os.listdir(os.path.join(train_path,category)):\r\n",
        "      train_data.append(['train/{}/{}'.format(category,file),file,category_id,category])\r\n",
        "  train_data = pd.DataFrame(train_data, columns=['file','filename', 'category_id', 'category'])\r\n",
        "  train_data.shape\r\n",
        "else:\r\n",
        "  print(\"train data already extracted\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VlZiEckEYyY"
      },
      "source": [
        "# one hot encoding target variable\r\n",
        "from keras.utils import np_utils\r\n",
        "categorical_labels = np_utils.to_categorical(train_data.category_id,num_classes=12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQa6rnMDE5hw"
      },
      "source": [
        "img_rows=128\r\n",
        "img_cols=128\r\n",
        "num_channel=3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTUK0nJpVEYi"
      },
      "source": [
        "#Import Test, Train & Validation Data\r\n",
        "\r\n",
        "#resizing the train image and save\r\n",
        "from tqdm import tqdm\r\n",
        "import cv2\r\n",
        "x_feature = []\r\n",
        "y_feature = []\r\n",
        "\r\n",
        "i = 0 # initialisation\r\n",
        "\r\n",
        "for f in tqdm(train_data.file):\r\n",
        "     # f for format ,jpg\r\n",
        "  train_img = cv2.imread(data_dir+'{}'.format(f))\r\n",
        "  label = categorical_labels[i]\r\n",
        "  train_img_resize = cv2.resize(train_img, (img_rows, img_cols),interpolation=cv2.INTER_LINEAR) \r\n",
        "  x_feature.append(train_img_resize)\r\n",
        "  y_feature.append(label)\r\n",
        "  i += 1\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qniVbe6VEYx"
      },
      "source": [
        "validation_seedlings = train_datagen.flow_from_directory(\r\n",
        "    '/content/drive/MyDrive/PlantClassification/train',\r\n",
        "    target_size=(128, 128),\r\n",
        "    batch_size=512,\r\n",
        "    class_mode='categorical',\r\n",
        "    subset='validation')\r\n",
        "\r\n",
        "x_val,y_val=next(validation_seedlings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VDVX7sNnjBD"
      },
      "source": [
        "x_train_data = np.array(x_feature, np.float32) / 255.   # /= 255 for normolisation\r\n",
        "print (x_train_data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bl4NSkHnntbl"
      },
      "source": [
        "y_train_data = np.array(y_feature)\r\n",
        "y_train_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u412UbnUnyO7"
      },
      "source": [
        "#Splitting train and validation set\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_data, y_train_data, test_size=0.2, random_state=2)\r\n",
        "print (x_train.shape)\r\n",
        "print (x_val.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IBmXaeAn7dX"
      },
      "source": [
        "#Generating augmented images using image generator\r\n",
        "datagen= tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=20,\r\n",
        "                                                         width_shift_range=0.2,\r\n",
        "                                                         height_shift_range=0.2,\r\n",
        "                                                         zoom_range=[0.4,1.5],\r\n",
        "                                                         horizontal_flip=True,\r\n",
        "                                                         vertical_flip=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy7dWqUwoA43"
      },
      "source": [
        "datagen.fit(x_train)\r\n",
        "print(datagen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzTQSZE_F1mz"
      },
      "source": [
        "from tensorflow.keras.layers import Flatten, InputLayer\r\n",
        "from tensorflow.keras.layers import Dense, Dropout\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gv6ryFGmmV77"
      },
      "source": [
        "#NN model for seedling data\n",
        "\n",
        "nn_model=Sequential()\n",
        "nn_model.add(Flatten(input_shape=(128,128,3)))\n",
        "nn_model.add(Dense(units = 840, activation = 'relu'))\n",
        "nn_model.add(Dropout(0.2))\n",
        "nn_model.add(Dense(units = 210, activation = 'relu'))\n",
        "nn_model.add(Dense(units = 210, activation = 'relu'))\n",
        "nn_model.add(Dropout(0.6))\n",
        "nn_model.add(Dense(units = 105, activation = 'relu'))\n",
        "nn_model.add(Dense(units = 12, activation = 'softmax'))\n",
        "nn_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kio7vuvoIcBb"
      },
      "source": [
        "adam = Adam(lr=0.0001)\n",
        "nn_model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "# Use earlystopping\n",
        "#callback = tensorflow.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, min_delta=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiX8oEyWhZP6"
      },
      "source": [
        "#fitting NN model\n",
        "with tf.device('/device:GPU:0'):\n",
        "  history = nn_model.fit(datagen.flow(x_train, y_train),\n",
        "          epochs=44,\n",
        "          steps_per_epoch= 100,  #Number of training images//batch_size\n",
        "          validation_data=(x_val,y_val),\n",
        "          validation_steps = 10, #Number of validation images//batch_size\n",
        "          #callbacks = [callback],\n",
        "          verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kktp_RKMpfj-"
      },
      "source": [
        "#Evaluating the model\n",
        "nn_prediction=nn_model.evaluate(x_val,y_val)\n",
        "print(nn_prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltYWd9Vcs4M7"
      },
      "source": [
        "### **Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4wQPrgZs8-D"
      },
      "source": [
        "* Dataset had 12 categories of plant seedling \r\n",
        "* All the images are resized to 224*224  \r\n",
        "* In Supervised Algorithm, K Nearest Neibour is used and the accuracy was around 10%\r\n",
        "* Fully connected neural network achieved 29% validation accuracy\r\n",
        "* CNN achieved 65% validation accuracy \r\n",
        "* It could be seen that accuracy is the maximum in CNN in comparison to Supervised / Fully Connected Neural network\r\n",
        "* Transfer Learning could also be a better choice for CNN "
      ]
    }
  ]
}
